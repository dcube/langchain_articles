{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import PyPDF2\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langserve import RemoteRunnable\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "chat_model = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-09-01-preview\",\n",
    "    azure_endpoint=os.getenv('AZURE_API_ENDPOINT'),\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    azure_deployment=os.getenv('OPENAI_DEPLOYMENT_NAME'),\n",
    "    model_name=os.getenv('OPENAI_MODEL_NAME'),\n",
    "    model_version=os.getenv('OPENAI_API_VERSION')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(pdf_path):\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page_num in range(len(reader.pages)):\n",
    "                page = reader.pages[page_num]\n",
    "                text += page.extract_text()\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConversationChain(ConversationChain):\n",
    "    def documentSummarizer(self, input):\n",
    "        file_path = input\n",
    "        article_content = getText(file_path)\n",
    "        article_summary = self.summarize_content(article_content)      \n",
    "        self.memory.save_context({\"input\": file_path}, {\"content\": article_content})       \n",
    "        return article_summary\n",
    "\n",
    "    def summarize_content(self, content):\n",
    "        summary_prompt = f\"Réalise un résumé concis du document : {content}\"\n",
    "        return self.llm.invoke(summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "chain = CustomConversationChain(\n",
    "    llm=chat_model,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeDoc(pdf_path) :\n",
    "    summary = chain.documentSummarizer(input=pdf_path)\n",
    "    print(summary)\n",
    "    \n",
    "def askQuestion(question):\n",
    "    response = chain.invoke(question)[\"response\"]\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
